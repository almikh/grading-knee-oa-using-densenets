{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ckpb03qq0r7T"
   },
   "source": [
    "#1. Грузим данные в нужном формате, описываем структуру сети и обучаем ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MV5d_15g05aK"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as dset\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vnntZ7Iae7u9"
   },
   "outputs": [],
   "source": [
    "# random seed and output dir setup\n",
    "import random\n",
    "\n",
    "frame_size = (224, 224)\n",
    "\n",
    "batch_size = 64\n",
    "random_seed = 42\n",
    "classes_header = [\"0\", \"1\", \"2\", \"3\", \"4\"] \n",
    "test_dataset_path = 'oai224/test'\n",
    "train_dataset_path = 'oai224/train'\n",
    "checkpoints_dir = 'DenseNet121_42/'\n",
    "random.seed(random_seed)\n",
    "np.random.seed(random_seed)\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "# if you are suing GPU\n",
    "torch.cuda.manual_seed(random_seed)\n",
    "torch.cuda.manual_seed_all(random_seed)\n",
    "\n",
    "torch.backends.cudnn.enabled = False \n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "FBrdbRytzh7f",
    "outputId": "5f319fcc-85ac-40ce-c98f-960c2e3cdcea"
   },
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "validation_split = .125\n",
    "\n",
    "# Разделяем данные на тренировочные и валидационные\n",
    "transforms_to_train = transforms.Compose([         \n",
    "              transforms.ColorJitter(brightness=.33, saturation=.33),\n",
    "              transforms.RandomHorizontalFlip(p=0.5),\n",
    "              transforms.RandomAffine(degrees=(-10, 10), scale=(0.9, 1.10)),\n",
    "              transforms.Resize(frame_size), \n",
    "\n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "train_dataset = datasets.ImageFolder(train_dataset_path, transform=transforms_to_train)\n",
    "targets = train_dataset.targets\n",
    "\n",
    "train_idx, valid_idx = model_selection.train_test_split(\n",
    "    np.arange(len(train_dataset.targets)), test_size=validation_split, random_state=42, shuffle=True, stratify=targets)\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "val_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=train_sampler, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, sampler=val_sampler, drop_last=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "id": "qrYfLdttzzUv",
    "outputId": "4f5bf5e3-b585-42d5-d5dd-4b0316e11f84"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if torch.cuda.is_available(): # Let's make sure GPU is available!\n",
    "    device = torch.device(\"cuda:0\")\n",
    "    device_name = 'cuda:0'\n",
    "    print(\"device: CUDA\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    device_name = 'cpu'\n",
    "    print(\"device: CPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3YtpzRENxTKq"
   },
   "outputs": [],
   "source": [
    "def weighted_loss(outputs, labels):\n",
    "    softmax_op = torch.nn.Softmax(1)\n",
    "    prob_pred = softmax_op(outputs)\n",
    "\n",
    "    def set_weights():\n",
    "        # weight matrix 04 (wm04)\n",
    "        init_weights = np.array([[1, 3, 6, 7, 9],\n",
    "                                 [4, 1, 4, 5, 7],\n",
    "                                 [6, 4, 1, 3, 5],\n",
    "                                 [7, 5, 3, 1, 3],\n",
    "                                 [9, 7, 5, 3, 1]], dtype=np.float)\n",
    "\n",
    "        adjusted_weights = init_weights + 1.0\n",
    "        np.fill_diagonal(adjusted_weights, 0)\n",
    "\n",
    "        return adjusted_weights\n",
    "    \n",
    "    cls_weights = set_weights()\n",
    "\n",
    "    batch_num, class_num = outputs.size()\n",
    "    class_hot = np.zeros([batch_num, class_num], dtype=np.float32)\n",
    "    labels_np = labels.data.cpu().numpy()\n",
    "    \n",
    "    for ind in range(batch_num):\n",
    "        class_hot[ind, :] = cls_weights[labels_np[ind], :]\n",
    "    class_hot = torch.from_numpy(class_hot)\n",
    "    class_hot = torch.autograd.Variable(class_hot).cuda()\n",
    "\n",
    "    loss = torch.sum((prob_pred * class_hot)**2) / batch_num\n",
    "    # loss = torch.mean(prob_pred * class_hot)\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "73a4C1Ebz9p9"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import utils\n",
    "\n",
    "def append_to_file(filename, val):\n",
    "    with open(filename, 'a') as f:\n",
    "        f.write(\"%s\\n\" % val)\n",
    "\n",
    "def read_file(filename):\n",
    "    lines = []\n",
    "    with open(filename, 'r') as f:\n",
    "        lines = [float(line.strip()) for line in f]\n",
    "\n",
    "    return lines\n",
    "\n",
    "def train_model(model, train_loader, val_loader, loss, optimizer, num_epochs, lr_scheduler = None, anneal_epoch = 0): \n",
    "    if not os.path.exists(checkpoints_dir):\n",
    "        os.makedirs(checkpoints_dir)\n",
    "\n",
    "    start_epoch = 0\n",
    "\n",
    "    open(checkpoints_dir + 'loss_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'train_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'val_history.txt', 'w').close()\n",
    "    open(checkpoints_dir + 'best_accuracy.txt', 'w').close()\n",
    "    print(\"start traning from scratch...\")\n",
    "\n",
    "    best_val_accuracy = 0\n",
    "\n",
    "    loss_history = []\n",
    "    train_history = []\n",
    "    val_history = []\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train() # Enter train mode\n",
    "        \n",
    "        loss_accum = 0\n",
    "        correct_samples = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # process batches\n",
    "        for i_step, (x, y) in enumerate(train_loader): \n",
    "            x_gpu = x.to(device)\n",
    "            y_gpu = y.to(device)\n",
    "            prediction = model(x_gpu)    \n",
    "\n",
    "            loss_value = loss(prediction, y_gpu)\n",
    "            # loss_value = weighted_loss(prediction, y_gpu)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            _, indices = torch.max(prediction, 1)\n",
    "            correct_samples += torch.sum(indices == y_gpu)\n",
    "            total_samples += y.shape[0]\n",
    "            \n",
    "            loss_accum += loss_value\n",
    "\n",
    "        # check accuracy\n",
    "        ave_loss = loss_accum / i_step\n",
    "        train_accuracy = float(correct_samples) / total_samples\n",
    "\n",
    "        val_accuracy = 0.0\n",
    "        with torch.no_grad():\n",
    "          val_accuracy, _, _, _ = utils.compute_accuracy(model, val_loader)\n",
    "\n",
    "        # write marks to files\n",
    "        append_to_file(checkpoints_dir + 'loss_history.txt', float(ave_loss))\n",
    "        append_to_file(checkpoints_dir + 'train_history.txt', train_accuracy)\n",
    "        append_to_file(checkpoints_dir + 'val_history.txt', val_accuracy)\n",
    "\n",
    "        # update learning rate\n",
    "        if lr_scheduler is not None and epoch >= anneal_epoch:\n",
    "          lr_scheduler.step()\n",
    "        \n",
    "        stage = epoch + start_epoch\n",
    "\n",
    "        if val_accuracy > best_val_accuracy:\n",
    "          best_val_accuracy = val_accuracy\n",
    "          \n",
    "          # next better model\n",
    "          model_save_name2 = 'model.ckpt-' + str(stage)\n",
    "          torch.save(model.state_dict(), checkpoints_dir + F\"{model_save_name2}\")\n",
    "          \n",
    "          # best model\n",
    "          model_save_name = 'best_model.ckpt'\n",
    "          torch.save(model.state_dict(), checkpoints_dir + F\"{model_save_name}\")\n",
    "\n",
    "          append_to_file(checkpoints_dir + 'best_accuracy.txt', best_val_accuracy)\n",
    "          print(\"update best model with val. accuracy %f on stage %d\" % (best_val_accuracy, stage))\n",
    "\n",
    "        print(\"epoch %d; average loss: %f, train accuracy: %f, val accuracy: %f\" % (stage, ave_loss, train_accuracy, val_accuracy))\n",
    "        \n",
    "    print(\"final best accuracy: %f\" % (best_val_accuracy))\n",
    "\n",
    "    return loss_history, train_history, val_history\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "7_HKIKFrCjhU",
    "outputId": "2148f9cd-eb1d-4a69-96b2-ac54cef8b036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start traning from scratch...\n",
      "update best model with val. accuracy 0.385417 on stage 0\n",
      "epoch 0; average loss: 1.515926, train accuracy: 0.367188, val accuracy: 0.385417\n"
     ]
    }
   ],
   "source": [
    "import custom_models\n",
    "\n",
    "cnn_model = custom_models.densenet121_model(5, use_pretrained=True)\n",
    "# cnn_model = custom_models.densenet161_model(num_class=5, use_pretrained=True)\n",
    "# cnn_model = custom_models.AntonyCnn(num_classes=2)\n",
    "\n",
    "# train model\n",
    "if device_name.startswith('cpu'):\n",
    "    cnn_model.type(torch.FloatTensor)\n",
    "    cnn_model.to(device)\n",
    "else:\n",
    "    cnn_model.type(torch.cuda.FloatTensor)\n",
    "    cnn_model.to(device)\n",
    "\n",
    "loss = nn.CrossEntropyLoss().type(torch.cuda.FloatTensor)\n",
    "optimizer = optim.Adam(cnn_model.parameters(), lr=1e-3, weight_decay=1e-4) # default: weight_decay=1e-4\n",
    "# optimizer = optim.SGD(cnn_model.parameters(), lr=1e-4, momentum=0.9, nesterov=True) \n",
    "\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.95) # decrease lr by 10% every 7 epochs\n",
    "\n",
    "loss_history, train_history, val_history = train_model(cnn_model, train_loader, val_loader, loss, optimizer, 71, lr_scheduler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-QIpuZWK7ec"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train_history = read_file(checkpoints_dir + 'train_history.txt')\n",
    "val_history = read_file(checkpoints_dir + 'val_history.txt')\n",
    "\n",
    "# vizualize accuracy\n",
    "plt.plot(train_history)\n",
    "plt.plot(val_history)\n",
    "plt.savefig(checkpoints_dir + 'graph.png')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Main.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "23dae643609f49d0bab5b0cd8670fab3": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "38e7a7d81083472fafbc008b01ae61a3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5d3257c1d2644c5b95549e1031cc17e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "69bfa5b5717643a7bf7c6d6fbd3908b4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c6fd2de1132b4561aa89dbef1e0717f4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5d3257c1d2644c5b95549e1031cc17e6",
      "placeholder": "​",
      "style": "IPY_MODEL_69bfa5b5717643a7bf7c6d6fbd3908b4",
      "value": " 30.8M/30.8M [00:00&lt;00:00, 127MB/s]"
     }
    },
    "d6a09f76263246a19b8fab8d0ab69715": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_f67a559f843b4726a8ca792110abae49",
       "IPY_MODEL_c6fd2de1132b4561aa89dbef1e0717f4"
      ],
      "layout": "IPY_MODEL_df2bfc187cd14a25922255bca08e8891"
     }
    },
    "df2bfc187cd14a25922255bca08e8891": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "f67a559f843b4726a8ca792110abae49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_38e7a7d81083472fafbc008b01ae61a3",
      "max": 32342954,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_23dae643609f49d0bab5b0cd8670fab3",
      "value": 32342954
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
