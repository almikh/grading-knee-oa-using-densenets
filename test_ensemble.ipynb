{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1Aewu3JZt5XH"
   },
   "source": [
    "#1. Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1389,
     "status": "ok",
     "timestamp": 1593417151055,
     "user": {
      "displayName": "Alexey M.",
      "photoUrl": "",
      "userId": "13008728338773453082"
     },
     "user_tz": -180
    },
    "id": "Y9PwncccuAVk"
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "import numpy as np\n",
    "import PIL\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset\n",
    "\n",
    "import torch.utils.data\n",
    "import torchvision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#2. Set main parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 5\n",
    "batch_size = 64\n",
    "frame_size = (224, 224)\n",
    "dataset_dir = 'dataset/oai224/test'\n",
    "\n",
    "# choose torch device\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#3. Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.sampler import SequentialSampler\n",
    "\n",
    "transforms_to_test = transforms.Compose([\n",
    "              transforms.Resize(frame_size), \n",
    "              transforms.ToTensor(),\n",
    "              transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "            ])\n",
    "\n",
    "test_dataset = datasets.ImageFolder(dataset_dir, transform=transforms_to_test)\n",
    "test_idx = list(range(len(test_dataset.imgs)))\n",
    "test_sampler = SequentialSampler(test_idx)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, sampler=test_sampler)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#5. Prepare ensembles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import custom_models\n",
    "\n",
    "class Ensemble(nn.Module):\n",
    "    def __init__(self, modelA, modelB, modelC, modelD = None):\n",
    "        super(Ensemble, self).__init__()\n",
    "        self.modelA = modelA\n",
    "        self.modelB = modelB\n",
    "        self.modelC = modelC\n",
    "        self.modelD = modelD\n",
    "      \n",
    "    def forward(self, x):\n",
    "        x1 = self.modelA(x)\n",
    "        x2 = self.modelB(x)\n",
    "        x3 = self.modelC(x)\n",
    "        \n",
    "        if modelD is None:\n",
    "            xx = x1.add(x2).add(x3)\n",
    "            return nn.functional.softmax(xx, 1)\n",
    "        else:\n",
    "            x4 = self.modelD(x)\n",
    "            xx = x1.add(x2).add(x3).add(x4)\n",
    "            return nn.functional.softmax(xx, 1)\n",
    "\n",
    "def make_3xdensenets_121_DRS():\n",
    "    cnn1 = custom_models.densenet121_model(n_classes)\n",
    "    cnn2 = custom_models.densenet121_model(n_classes)\n",
    "    cnn3 = custom_models.densenet121_model(n_classes)\n",
    "\n",
    "    cnn1.load_state_dict(torch.load('models/densenet121_21.ckpt', map_location=torch.device(device)))\n",
    "    cnn2.load_state_dict(torch.load('models/densenet121_42.ckpt', map_location=torch.device(device)))  \n",
    "    cnn3.load_state_dict(torch.load('models/densenet121_84.ckpt', map_location=torch.device(device)))  \n",
    "\n",
    "    cnn_model = Ensemble(cnn1, cnn2, cnn3)\n",
    "    cnn_model.type(torch.FloatTensor)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "def make_3xdensenets_121_DCH():\n",
    "    cnn1 = custom_models.densenet121_model(n_classes)\n",
    "    cnn2 = custom_models.densenet121_model(n_classes)\n",
    "    cnn3 = custom_models.densenet121_model(n_classes)\n",
    "\n",
    "    cnn1.load_state_dict(torch.load('models/densenet121_42.ckpt', map_location=torch.device(device)))\n",
    "    cnn2.load_state_dict(torch.load('models/densenet121_42.ckpt-15', map_location=torch.device(device)))  \n",
    "    cnn3.load_state_dict(torch.load('models/densenet121_42.ckpt-18', map_location=torch.device(device)))  \n",
    "\n",
    "    cnn_model = Ensemble(cnn1, cnn2, cnn3)\n",
    "    cnn_model.type(torch.FloatTensor)\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "# def make_3xdensenets_161_DRS():\n",
    "#     cnn1 = custom_models.densenet161_model(n_classes)\n",
    "#     cnn2 = custom_models.densenet161_model(n_classes)\n",
    "#     cnn3 = custom_models.densenet161_model(n_classes)\n",
    "# \n",
    "#     cnn1.load_state_dict(torch.load('models/densenet161_21.ckpt', map_location=torch.device(device)))\n",
    "#     cnn2.load_state_dict(torch.load('models/densenet161_42.ckpt', map_location=torch.device(device)))  \n",
    "#     cnn3.load_state_dict(torch.load('models/densenet161_84.ckpt', map_location=torch.device(device)))  \n",
    "# \n",
    "#     cnn_model = Ensemble(cnn1, cnn2, cnn3)\n",
    "#     cnn_model.type(torch.FloatTensor)\n",
    "#     \n",
    "#     return cnn_model\n",
    "\n",
    "# def make_3xdensenets_161_DCH():\n",
    "#     cnn1 = custom_models.densenet161_model(n_classes)\n",
    "#     cnn2 = custom_models.densenet161_model(n_classes)\n",
    "#     cnn3 = custom_models.densenet161_model(n_classes)\n",
    "# \n",
    "#     cnn1.load_state_dict(torch.load('models/densenet161_84.ckpt', map_location=torch.device(device)))\n",
    "#     cnn2.load_state_dict(torch.load('models/densenet161_84.ckpt-22', map_location=torch.device(device)))  \n",
    "#     cnn3.load_state_dict(torch.load('models/densenet161_84.ckpt-23', map_location=torch.device(device)))  \n",
    "# \n",
    "#     cnn_model = Ensemble(cnn1, cnn2, cnn3)\n",
    "#     cnn_model.type(torch.FloatTensor)\n",
    "#    \n",
    "#     return cnn_model\n",
    "\n",
    "def make_4xdensenets_121_161():\n",
    "    cnn1 = custom_models.densenet121_model(n_classes)\n",
    "    cnn2 = custom_models.densenet121_model(n_classes)\n",
    "    cnn3 = custom_models.densenet161_model(n_classes)\n",
    "    # cnn4 = custom_models.densenet161_model(n_classes)\n",
    "\n",
    "    cnn1.load_state_dict(torch.load('models/densenet121_21.ckpt', map_location=torch.device(device)))\n",
    "    cnn2.load_state_dict(torch.load('models/densenet121_42.ckpt', map_location=torch.device(device)))  \n",
    "    cnn3.load_state_dict(torch.load('models/densenet161_42.ckpt', map_location=torch.device(device)))   \n",
    "    # cnn4.load_state_dict(torch.load('models/densenet161_84.ckpt', map_location=torch.device(device))) \n",
    "\n",
    "    cnn_model = Ensemble(cnn1, cnn2, cnn3)\n",
    "    cnn_model.type(torch.FloatTensor)\n",
    "    \n",
    "    return cnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_model = make_3xdensenets_121_DRS()\n",
    "# cnn_model = make_3xdensenets_121_DCH()\n",
    "# cnn_model = make_3xdensenets_161_DRS()\n",
    "# cnn_model = make_3xdensenets_161_DCH()\n",
    "# cnn_model = make_4xdensenets_121_161()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#6. Check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "\n",
    "total_params = sum(p.numel() for p in cnn_model.parameters())\n",
    "total_trainable_params = sum(p.numel() for p in cnn_model.parameters() if p.requires_grad)\n",
    "print(\"parameters number: \", total_params)\n",
    "print(\"trainable parameters number: \", total_trainable_params)\n",
    "\n",
    "predictions = []\n",
    "raw_predictions = []\n",
    "ground_truth = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  print(\"compute accuracy...\")\n",
    "  test_accuracy, predictions, ground_truth, raw_predictions = utils.compute_accuracy(cnn_model, test_loader)\n",
    "  print(\"test accuracy:\", test_accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#7. Calculate metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 529840,
     "status": "ok",
     "timestamp": 1593417679614,
     "user": {
      "displayName": "Alexey M.",
      "photoUrl": "",
      "userId": "13008728338773453082"
     },
     "user_tz": -180
    },
    "id": "4-3XHWWp_nXr",
    "outputId": "6eb9cb59-6200-410c-efdc-af0d3bc05aee"
   },
   "outputs": [],
   "source": [
    "import sklearn.metrics as metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def performance_matrix(true,pred):\n",
    "    precision = metrics.precision_score(true,pred,average='weighted')\n",
    "    recall = metrics.recall_score(true,pred,average='weighted') # average='weighted'\n",
    "    accuracy = metrics.accuracy_score(true,pred)\n",
    "    f1_score = metrics.f1_score(true,pred,average='weighted')\n",
    "    print('Mean \\n  precision: {} \\n  recall: {}, \\n  accuracy: {}, \\n  f1_score: {}'.format(precision*100,recall*100,accuracy*100,f1_score*100))\n",
    "\n",
    "performance_matrix(ground_truth, predictions)\n",
    "\n",
    "# \n",
    "from tabulate import tabulate\n",
    "from sklearn.metrics import precision_recall_fscore_support as score\n",
    "precision, recall, fscore, support = score(ground_truth, predictions)\n",
    "\n",
    "print('\\n')\n",
    "print('rows is precision, recall, fscore and support:')\n",
    "print(tabulate([precision, recall, fscore, support], headers=['0' , '1' , '2' , '3', '4'], tablefmt='orgtbl'))\n",
    "\n",
    "print('\\n')\n",
    "print('per-class accuracy:')\n",
    "cm = confusion_matrix(ground_truth, predictions)\n",
    "cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "print(tabulate([cm.diagonal()], headers=['0' , '1' , '2' , '3', '4'], tablefmt='orgtbl'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 416
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 530426,
     "status": "ok",
     "timestamp": 1593417680215,
     "user": {
      "displayName": "Alexey M.",
      "photoUrl": "",
      "userId": "13008728338773453082"
     },
     "user_tz": -180
    },
    "id": "3GZq5nFiP2Eu",
    "outputId": "cd23dd25-d0e7-4ddd-c288-402c5f8be952"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_true, y_pred, classes,\n",
    "                          normalize=False,\n",
    "                          title=None,\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if not title:\n",
    "        if normalize:\n",
    "            title = 'Normalized confusion matrix'\n",
    "        else:\n",
    "            title = 'Confusion matrix, without normalization'\n",
    "            \n",
    "    # Compute confusion matrix\n",
    "    cm = metrics.confusion_matrix(y_true, y_pred)\n",
    "    # Only use the labels that appear in the data\n",
    "    #classes = classes[unique_labels(y_true, y_pred)]\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    im = ax.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    ax.figure.colorbar(im, ax=ax)\n",
    "    # We want to show all ticks...\n",
    "    ax.set(xticks=np.arange(cm.shape[1]),\n",
    "           yticks=np.arange(cm.shape[0]),\n",
    "           # ... and label them with the respective list entries\n",
    "           xticklabels=classes, yticklabels=classes,\n",
    "           title=title,\n",
    "           ylabel='True label',\n",
    "           xlabel='Predicted label')\n",
    "    # Rotate the tick labels and set their alignment.\n",
    "    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"right\",\n",
    "             rotation_mode=\"anchor\")\n",
    "    # Loop over data dimensions and create text annotations.\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            ax.text(j, i, format(cm[i, j], fmt),\n",
    "                    ha=\"center\", va=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    fig.tight_layout()\n",
    "    return ax\n",
    "\n",
    "\n",
    "plot_confusion_matrix(ground_truth, predictions, classes=[\"0\", \"1\", \"2\", \"3\", \"4\"],title='Confusion matrix, without normalization')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scikitplot as skplt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "y_score = np.array(raw_predictions)\n",
    "y_test = ground_truth\n",
    "\n",
    "# Binarize the output\n",
    "if n_classes == 2:\n",
    "    _classes= [0, 1]\n",
    "    colors =  ['blue', 'red']\n",
    "    y_test = label_binarize(y_test, range(n_classes+1))[:,:-1]\n",
    "else:\n",
    "    _classes= [0, 1, 2, 3, 4]\n",
    "    colors = ['purple', 'green', 'blue', 'red', 'black']\n",
    "    y_test = label_binarize(y_test, classes=_classes,neg_label=0, pos_label=1, sparse_output=False)\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [9, 5]\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "    \n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color,\n",
    "             label='ROC curve for grade {0} (AUC = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "    \n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic for multi-class data')\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMHLlianmzcIwJIaHSE/KgF",
   "collapsed_sections": [],
   "name": "Ensembles 2.0.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
